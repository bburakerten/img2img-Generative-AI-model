# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yzREyvZez00x-8JANTpfqCCeTpKC1iIC
"""

!pip install diffusers transformers accelerate torch

import torch
from diffusers import StableDiffusionPipeline

model_id = "runwayml/stable-diffusion-v1-5"  # Stable Diffusion v1.5 model
pipe = StableDiffusionPipeline.from_pretrained(
    model_id, torch_dtype=torch.float16
)
pipe = pipe.to("cuda")  # move pipeline to GPU

base_description = "a portrait of a young man with short brown hair and green eyes, soft studio lighting, high quality"
prompt_no_beard = base_description + ", clean-shaven face, no beard"
prompt_with_beard = base_description + ", with a well-groomed thick beard"

seed = 42
generator = torch.Generator(device="cuda").manual_seed(seed)

result_no_beard = pipe(prompt_no_beard, generator=generator, guidance_scale=7.5)
image_no_beard = result_no_beard.images[0]

generator = torch.Generator(device="cuda").manual_seed(seed)
result_beard = pipe(prompt_with_beard, generator=generator, guidance_scale=7.5)
image_with_beard = result_beard.images[0]

image_no_beard.save("example_no_beard.png")
image_with_beard.save("example_with_beard.png")

from diffusers import StableDiffusionImg2ImgPipeline

img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    model_id, torch_dtype=torch.float16
).to("cuda")

init_image = image_no_beard.convert("RGB")
result_beard_img2img = img2img_pipe(prompt_with_beard, image=init_image, strength=0.5, guidance_scale=7.5)
image_with_beard_v2 = result_beard_img2img.images[0]
image_with_beard_v2.save("example_with_beard_img2img.png")

import os
from tqdm import trange

out_dir = "paired_faces_512"
os.makedirs(out_dir, exist_ok=True)

base_seed = 1000
num_pairs = 100

for i in trange(num_pairs, desc="Generating pairs"):
    seed = base_seed + i
    gen = torch.Generator(device="cuda").manual_seed(seed)
    img_no_beard = pipe(prompt_no_beard, generator=gen, guidance_scale=7.5).images[0]
    gen = torch.Generator(device="cuda").manual_seed(seed)
    img_beard = pipe(prompt_with_beard, generator=gen, guidance_scale=7.5).images[0]
    img_no_beard.save(f"{out_dir}/person_{i:03d}_nobeard.png")
    img_beard.save(f"{out_dir}/person_{i:03d}_beard.png")

from PIL import Image

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows * cols
    w, h = imgs[0].size
    grid_img = Image.new("RGB", size=(cols * w, rows * h))
    for idx, img in enumerate(imgs):
        grid_x = (idx % cols) * w
        grid_y = (idx // cols) * h
        grid_img.paste(img, (grid_x, grid_y))
    return grid_img

sample_imgs = []
for j in range(10):
    no_beard_img = Image.open(f"{out_dir}/person_{j:03d}_nobeard.png")
    beard_img    = Image.open(f"{out_dir}/person_{j:03d}_beard.png")
    no_beard_img = no_beard_img.resize((512,512))
    beard_img    = beard_img.resize((512,512))
    sample_imgs.extend([no_beard_img, beard_img])

grid = image_grid(sample_imgs, rows=10, cols=2)
grid.save("preview_grid.png")
grid



#!/usr/bin/env python3
"""
beard_img2img.py

Train & test a lightweight Pix2Pix‐style img2img model
(bearded → clean‐shaven) at 256×256 resolution.
All settings are hard‐coded so you can just run `python beard_img2img.py`
"""

import os
from types import SimpleNamespace

from PIL import Image
import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
from matplotlib import pyplot as plt

# --------------------------------------------------
#  Dataset
# --------------------------------------------------
class BeardPairDataset(Dataset):
    def __init__(self, root_dir, resolution=256):
        self.root = root_dir
        files = sorted(f for f in os.listdir(root_dir) if f.endswith(".png"))
        self.ids = sorted({f.split('_')[1] for f in files})
        self.tf = T.Compose([
            T.Resize((resolution, resolution)),
            T.ToTensor(),
            T.Normalize((0.5,)*3, (0.5,)*3)
        ])
    def __len__(self):
        return len(self.ids)
    def __getitem__(self, idx):
        sid = self.ids[idx]
        A = Image.open(os.path.join(self.root, f"person_{sid}_beard.png")).convert("RGB")
        B = Image.open(os.path.join(self.root, f"person_{sid}_nobeard.png")).convert("RGB")
        return self.tf(A), self.tf(B)

# --------------------------------------------------
#  Models
# --------------------------------------------------
class UNetGenerator(nn.Module):
    def __init__(self, base_ch=32):
        super().__init__()
        self.enc1 = nn.Sequential(nn.Conv2d(3, base_ch, 4,2,1), nn.LeakyReLU(0.2))
        self.enc2 = nn.Sequential(nn.Conv2d(base_ch, base_ch*2, 4,2,1),
                                  nn.BatchNorm2d(base_ch*2), nn.LeakyReLU(0.2))
        self.enc3 = nn.Sequential(nn.Conv2d(base_ch*2, base_ch*4, 4,2,1),
                                  nn.BatchNorm2d(base_ch*4), nn.LeakyReLU(0.2))
        self.bot  = nn.Sequential(nn.Conv2d(base_ch*4, base_ch*8, 4,2,1), nn.ReLU())
        self.dec3 = nn.Sequential(nn.ConvTranspose2d(base_ch*8, base_ch*4, 4,2,1),
                                  nn.BatchNorm2d(base_ch*4), nn.ReLU())
        self.dec2 = nn.Sequential(nn.ConvTranspose2d(base_ch*8, base_ch*2, 4,2,1),
                                  nn.BatchNorm2d(base_ch*2), nn.ReLU())
        self.dec1 = nn.Sequential(nn.ConvTranspose2d(base_ch*4, base_ch,   4,2,1),
                                  nn.BatchNorm2d(base_ch),   nn.ReLU())
        self.out  = nn.ConvTranspose2d(base_ch*2, 3, 4,2,1)
    def forward(self, x):
        e1 = self.enc1(x); e2 = self.enc2(e1); e3 = self.enc3(e2)
        b = self.bot(e3)
        d3 = self.dec3(b)
        d2 = self.dec2(torch.cat([d3,e3],1))
        d1 = self.dec1(torch.cat([d2,e2],1))
        return torch.tanh(self.out(torch.cat([d1,e1],1)))

class PatchDiscriminator(nn.Module):
    def __init__(self, base_ch=32):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(6, base_ch,   4,2,1), nn.LeakyReLU(0.2),
            nn.Conv2d(base_ch, base_ch*2, 4,2,1), nn.BatchNorm2d(base_ch*2), nn.LeakyReLU(0.2),
            nn.Conv2d(base_ch*2, base_ch*4, 4,2,1), nn.BatchNorm2d(base_ch*4), nn.LeakyReLU(0.2),
            nn.Conv2d(base_ch*4, 1, 4,1,1)
        )
    def forward(self, x):
        return self.net(x)

# --------------------------------------------------
#  Checkpoint Utils
# --------------------------------------------------
def save_ckpt(model, opt, epoch, d, name):
    os.makedirs(d, exist_ok=True)
    path = os.path.join(d, f"{name}_epoch{epoch:03d}.pt")
    torch.save({"model":model.state_dict(), "opt":opt.state_dict()}, path)

def load_ckpt(model, path, device):
    ck = torch.load(path, map_location=device)
    model.load_state_dict(ck["model"])

# --------------------------------------------------
#  Training
# --------------------------------------------------
def train_model(args):
    ds = BeardPairDataset(args.data_root, args.resolution)
    dl = DataLoader(ds, batch_size=args.batch_size, shuffle=True, num_workers=2, pin_memory=True)
    device = torch.device(args.device)
    G = UNetGenerator().to(device)
    D = PatchDiscriminator().to(device)
    optG = Adam(G.parameters(), lr=args.lr, betas=(0.5,0.999))
    optD = Adam(D.parameters(), lr=args.lr, betas=(0.5,0.999))
    lossBCE = nn.BCEWithLogitsLoss()
    lossL1  = nn.L1Loss()
    real, fake = 1.0, 0.0

    for ep in range(1, args.epochs+1):
        for A,B in dl:
            A,B = A.to(device), B.to(device)
            # D real
            D_real = D(torch.cat([A,B],1))
            lD_real = lossBCE(D_real, torch.full_like(D_real, real))
            # D fake
            fake_B = G(A)
            D_fake = D(torch.cat([A,fake_B.detach()],1))
            lD_fake = lossBCE(D_fake, torch.full_like(D_fake, fake))
            lD = 0.5*(lD_real+lD_fake)
            optD.zero_grad(); lD.backward(); optD.step()
            # G step
            Df = D(torch.cat([A,fake_B],1))
            lG = lossBCE(Df, torch.full_like(Df, real)) + 100*lossL1(fake_B,B)
            optG.zero_grad(); lG.backward(); optG.step()

        print(f"Epoch {ep}/{args.epochs}  lossD {lD.item():.4f}  lossG {lG.item():.4f}")
        save_ckpt(G,optG,ep,args.checkpoint_dir,"G")

    return os.path.join(args.checkpoint_dir, f"G_epoch{args.epochs:03d}.pt")

# --------------------------------------------------
#  Testing & Saving
# --------------------------------------------------
def test_and_save(args, ckpt, out_path="/content/test_results.png"):
    ds = BeardPairDataset(args.data_root, args.resolution)
    dl = DataLoader(ds, batch_size=args.test_batch_size, shuffle=False)
    device = torch.device(args.device)
    G = UNetGenerator().to(device)
    load_ckpt(G, ckpt, device)
    G.eval()

    A,B = next(iter(dl))
    A = A.to(device)
    with torch.no_grad():
        fake_B = G(A)

    n = min(5, A.size(0))
    fig,axs = plt.subplots(n,3,figsize=(9,3*n))
    for i in range(n):
        for j,img in enumerate((A,B.to(device),fake_B)):
            im = img[i].cpu().permute(1,2,0)*0.5+0.5
            axs[i,j].imshow(im.clamp(0,1))
            axs[i,j].axis("off")
    axs[0,0].set_title("Bearded")
    axs[0,1].set_title("Clean GT")
    axs[0,2].set_title("Pred Clean")
    plt.tight_layout()

    fig.savefig(out_path)
    print(f"✔ Test results image saved to: {out_path}")

# --------------------------------------------------
#  Main
# --------------------------------------------------
if __name__ == "__main__":
    # hard-coded settings
    args = SimpleNamespace(
        data_root       = "/content/paired_faces_512",
        checkpoint_dir  = "/content/checkpoints",
        epochs          = 30,
        batch_size      = 16,
        test_batch_size = 8,
        resolution      = 256,
        lr              = 2e-4,
        device          = "cuda",
    )
    os.makedirs(args.checkpoint_dir, exist_ok=True)

    print("▶ Starting training…")
    final_ckpt = train_model(args)
    print(f"✔ Training complete. Checkpoint: {final_ckpt}\n")

    print("▶ Running test + saving results…")
    test_and_save(args, final_ckpt, out_path="/content/test_results.png")
    print("✅ All done!")



